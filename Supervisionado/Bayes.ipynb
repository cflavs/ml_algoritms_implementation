{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas utilizadas\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Database\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - Dataset\n",
    "\n",
    "Ao iniciar qualquer experimento com Inteligência Artificial, o primeiro passo, e um dos mais importantes, é compreender o problema interpretando a base de dados escolhida. Dessa forma, nesta parte deve-se:\n",
    "* Carregar o dataset\n",
    "* Analisar os atributos, excluindo atributos irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(filename, classIndex):\n",
    "    \"\"\"Função de leitura e preprocessamento do dataset, recebe como entrada o nome do \n",
    "    arquivo e o indice do atributo alvo. Essa função retorna o dataframe de forma\n",
    "    que o atributo alvo esteja na última coluna.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename, delimiter=';')\n",
    "    df_classes = df.iloc[:,classIndex] \n",
    "    #deleta colunas, para remover outras colunas, deve-se adicionar seus índices entre os \n",
    "    #colchetes, separados por vírgula após a variável classIndex\n",
    "    df.drop(df.columns[[classIndex]], axis=1, inplace=True)\n",
    "    df['Hotel Stars'] = df_classes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - Calcular as frequências da saída \n",
    "\n",
    "No aprendizado bayesiano, probabilidades condicionais são calculadas a partir do atributo alvo.\n",
    "Dessa forma, a etapa inicial é analisar todas as instâncias e calcular a frequência de cada\n",
    "classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFreq(df, index):\n",
    "    \"\"\"Função que calcula a frequência das classes de saída, recebe como entrada o dataframe\n",
    "    completo e o índice da coluna dos atributos alvo.\n",
    "    Retorna um dicionário com a frequêNcia de cada classe e os respectivos nomes;\n",
    "    \"\"\"\n",
    "    outputNames = df.iloc[:,index].unique()\n",
    "    totalOutputFreq = df.iloc[:,index].count()\n",
    "    classesDic = {}\n",
    "    for i in range(len(outputNames)):\n",
    "        outputFreq = df.iloc[:,index][df.iloc[:,index] == outputNames[i]].count()\n",
    "        classesDic[i] = [outputFreq, outputFreq/totalOutputFreq]\n",
    "    return outputNames, classesDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3 - Treinamento\n",
    "\n",
    "Calculadas as frequências das classes, o Naive Bayes irá calcular a probabilidade de cada \n",
    "atributo. Para isso, deve-se, para cada coluna, calcular a probabilidade condicional desse \n",
    "algoritmo dado uma saída X. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def training(df, outputNames, classIndex):\n",
    "    \"\"\"Recebe como entrada o dataframe completo, o índice do atributo alvo e os nomes\n",
    "    das classes. Para cada instância, busca o valor de um atributo e calcula a probabilidade\n",
    "    condicional do mesmo para todas as classes. Esse processo é repetido até que todos os \n",
    "    atributos sejam analisados\n",
    "    Retorna: um dicionário com todas as probabilidades de todos os valores das instâncias;\n",
    "    \"\"\"\n",
    "    dic = defaultdict(dict)\n",
    "    dicNames = defaultdict(dict)\n",
    "    for j in range(len(outputNames)): #para todas as classes\n",
    "        for i in range(df.shape[1]-1): #percorre até que todos os atributos sejam analisados\n",
    "            attributeNames = df.iloc[:,i].unique() #retorna os valores do atributo atual\n",
    "            dicNames[j][i] = attributeNames #adiciona o nome do atributo ao dicionário\n",
    "            prob = np.ones(len(attributeNames))\n",
    "            for k in range(len(attributeNames)): #para cada valor de atributo, calcular a probabilidade\n",
    "                prob[k] = df.iloc[:,classIndex][(df.iloc[:,classIndex] == outputNames[j])][df.iloc[:,i]== attributeNames[k]].count()\n",
    "                if prob[k] == 0:\n",
    "                    prob[k] == 0.1\n",
    "            dic[j][i] = prob #adiciona no dicionário\n",
    "    return dic, dicNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4 - Teste\n",
    "\n",
    "Com as probabilidades obtidas com a base de treinamento, precisa-se verificar o sucesso do algoritmo\n",
    "com novas instâncias. Para isso, deve-se primeiramente fazer uma busca no dicionário o valor\n",
    "de cada atributo da instância analisada, caso esse valor não exista no dicionário, deve-se adicionar\n",
    "uma probabilidade igual a 0.01, caso esse valor exista, a probabilidade do atributo é retornada \n",
    "dividindo-se pela frequência da classe. Esse processo repete-se para cada atributo da instância,\n",
    "de forma que a probabilidade final é uma multiplicação de todos os atributos dessa instância. \n",
    "Ao final, multiplica-se a probabilidade obtida pela probabilidade da classe atual, sendo essa\n",
    "a probabilidade final da instância. \n",
    "\n",
    "O processo é repetido para todas as classes de cada instância até que todas as instâncias e\n",
    "classes sejam analisadas. Onde a predição final de cada instância será dada pela classe com\n",
    "maior probabilidade encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(training, outputNames,dic,dicNames,classesDic):\n",
    "    p = [[]]\n",
    "    y_pred = []\n",
    "    for i in range(len(training)): #para cada instância do treinamento\n",
    "        for k in range(len(outputNames)): #para cada classe \n",
    "            prob = 1\n",
    "            for j in range(len(training[i])-1): #para cada atributo da instância\n",
    "                index = np.where(dicNames[k][j]==training[i][j]) #encontre o valor do atributo no dicionário\n",
    "                if np.array(index).size==0: #se não existir, adicione uma probabilidade baixa\n",
    "                    prob*=0.01\n",
    "                else: #se existir, recupere a probabilidade do valor encontrado e divida pela frequencia da classe analisada\n",
    "                    prob*=(dic[k][j][index]/classesDic[k][0]) #multiplique o valor encontrado pelo valor dos demais atributos da instacia\n",
    "            prob*=classesDic[k][1] #multiplique a probabilidade de todos os atributos pela probabilidade da classe\n",
    "            p[i].append(prob) #guarde todas as probabilidades encontradas \n",
    "        y_pred.append(np.argmax(p[i])) #retorne o índice da classe que obtiver maior probabilidade\n",
    "        if i < len(training):\n",
    "            p.append([])\n",
    "    return y_pred,p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeLabels(X_test,outputNames):\n",
    "    \"\"\"Função auxiliar para codificar a saída de acordo com os valores das classes encontrados\n",
    "    no dicionário, considerando que o dicionário pode ordenar as classes com índices diferentes\n",
    "    dos índices da saída.\n",
    "    Recebe como entrada a base de treino eos nomes das classes\n",
    "    Retorna a saída codificada\n",
    "    \"\"\"\n",
    "    y_test = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(len(outputNames)):\n",
    "            if X_test.iloc[i,19] == outputNames[j]:\n",
    "                y_test.append(j)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes():\n",
    "    df = readDataset('LasVegasTripAdvisorReviews-Dataset.csv',14)\n",
    "    X_train, X_test = train_test_split(df, test_size=0.33,random_state=0)\n",
    "    outputNames,classesDic = getOutputFreq(X_train,19)\n",
    "    print(outputNames)\n",
    "    dic,dicNames = training(X_train, outputNames,19)\n",
    "    y_pred,p = test(df.values,outputNames,dic,dicNames,classesDic)\n",
    "    y_test = decodeLabels(df, outputNames)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return  accuracy_score(y_test, y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '4' '5' '4,5' '3,5']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      1.00      0.76        96\n",
      "          1       1.00      0.82      0.90       120\n",
      "          2       1.00      0.93      0.96       192\n",
      "          3       1.00      0.71      0.83        24\n",
      "          4       1.00      0.74      0.85        72\n",
      "\n",
      "avg / total       0.93      0.88      0.89       504\n",
      "\n",
      "[[ 96   0   0   0   0]\n",
      " [ 22  98   0   0   0]\n",
      " [ 14   0 178   0   0]\n",
      " [  7   0   0  17   0]\n",
      " [ 19   0   0   0  53]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87698412698412698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
